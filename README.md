
##  Overview

Fake or paid reviews can mislead users and damage trust on online platforms.  
Instead of treating fake review detection as a strict binary classification problem, this project implements an **explainable risk-based system** that estimates how suspicious a review is.

The system outputs a **Suspicion Score (0â€“100)** and categorizes reviews into:
- ðŸŸ¢ Low Risk  
- ðŸŸ  Medium Risk  
- ðŸ”´ High Risk  

This approach aligns with how real-world platforms handle deceptive content.



##  Key Features

- Risk-based prediction instead of fake/genuine labeling  
- Hybrid approach: Machine Learning + Rule-Based heuristics  
- Word-level and Character-level TF-IDF feature extraction  
- Explainable output with score breakdown  
- Interactive Streamlit web application  


##  Dataset

- **Dataset:** Yelp Fake Review Dataset  
- **Labels:**
  - `0` â†’ Genuine  
  - `1` â†’ Fake  

### Why this dataset?
- Realistic and noisy
- Fake reviews closely resemble genuine ones
- Highlights limitations of text-only ML
- Commonly used in research and benchmarking



##  System Architecture
User Review
â†“
Text Preprocessing
â†“
Word + Character TF-IDF
â†“
Logistic Regression (ML Risk Score)
â†“
Rule-Based Heuristics
â†“
Weighted Aggregation
â†“
Final Suspicion Score (0â€“100)


---

## ðŸ”§ Machine Learning Pipeline

### Text Preprocessing
- Lowercasing
- Stopword removal
- Lemmatization

### Feature Engineering
- **Word TF-IDF (1â€“2 grams):** captures semantic meaning  
- **Character TF-IDF (3â€“5 grams):** captures stylistic patterns such as repetition and emphasis  

### Model
- **Logistic Regression**
  - Suitable for sparse, high-dimensional text data
  - Interpretable and stable
  - Industry-standard baseline for NLP tasks



##  Rule-Based Heuristics

To improve explainability and robustness, rule-based signals were added:

- Very short reviews  
- Excessive exclamation marks  
- Uppercase emphasis  
- Marketing phrases (e.g., *best ever*, *must buy*)  
- Low vocabulary diversity  

Each rule contributes to a rule-based risk score.


##  Aggregation Strategy

Final suspicion score is calculated as:
Final Risk Score = (0.7 Ã— ML Risk Score) + (0.3 Ã— Rule-Based Risk Score)


This balances learned linguistic patterns with deterministic signals.



## Web Application

The Streamlit application allows users to:
1. Enter a review
2. Analyze its suspiciousness
3. View:
   - Final risk score
   - Risk category
   - ML vs rule-based score breakdown



##  Project Structure

fake-review-detection/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ fake_review_model.pkl
â”‚ â”œâ”€â”€ word_vectorizer.pkl
â”‚ â””â”€â”€ char_vectorizer.pkl
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â””â”€â”€ rules.py
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ reviews.csv
â”‚
â””â”€â”€ README.md

## Sample Inputs
ðŸ”´ High Risk
BEST PRODUCT EVER!!! LIFE CHANGING!!! MUST BUY!!!
Highly recommended to everyone!!!

ðŸŸ¢ Low Risk
I visited the restaurant with my family on Sunday evening.
We ordered dosa and coffee. Food arrived in about 15 minutes.
Parking was limited but overall experience was good.

## Note on Accuracy

Fake review detection is a fraud-style problem.
On realistic datasets, classical ML models typically plateau around 65â€“75% accuracy.

This project prioritizes:

Correct problem framing

Explainability

Practical usability over raw accuracy 
